# Deaf_Talk
An Assitive Technology To Enhance  Interaction Between Deaf Mute Individuals and Normal People using urdu sign language.

Social integration and everyday communication require effective interaction. Hearing- and speech-impaired individuals, especially within Urdu-speaking communities, face significant barriers due to the lack of inclusive communication tools. Existing assistive technologies primarily support American Sign Language (ASL) and often provide only one-way communication, which is insufficient for Urdu Sign Language (USL) users and limits inclusivity in diverse linguistic contexts.

This project presents a smartphone-based application that facilitates two-way communication using Urdu Sign Language (USL). The system employs computer vision and gesture recognition techniques to convert hand gestures into textual and audio outputs. Additionally, speech and text recognition features are implemented to transform spoken or written language into sign language through pre-recorded gesture videos, enabling effective communication between hearing individuals and those with hearing or speech impairments.

A key contribution of this work is the development of a real-time gesture recognition and translation system that supports bidirectional translation between hand gestures and text/voice outputs. The system demonstrates reliability and provides a satisfactory user experience by accurately recognizing gestures, with fast and responsive translations achieved through pre-recorded gesture representations. Experimental results show high gesture detection accuracy and effective real-time translation performance.

This project addresses the limitations of existing solutions for the Urdu-speaking deaf and mute community by integrating USL into a two-way translation framework. It promotes digital accessibility and contributes to more inclusive communication.
